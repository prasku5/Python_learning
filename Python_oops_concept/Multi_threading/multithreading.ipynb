{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Threading Basics\n",
    "# Thread Lifecycle: Understand thread creation, starting a thread, and how a thread terminates.\n",
    "# threading.Thread Class: Learn to create and manage threads using the threading module, and how\n",
    "#  to pass arguments to threads.\n",
    "# join() Method: Blocking a thread until another thread completes. This is essential to prevent\n",
    "#  race conditions or ensure proper task sequencing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting threads...\n",
      "Thread Thread 1 started\n",
      "Thread Thread 2 started\n",
      "Thread 2: 6\n",
      "Thread 1: 1Thread 2: 7\n",
      "\n",
      "Thread 2: 8\n",
      "Thread 1: 2\n",
      "Thread 2: 9\n",
      "Thread 2: 10\n",
      "Thread Thread 2 finished\n",
      "Thread 1: 3\n",
      "Thread 1: 4\n",
      "Thread 1: 5\n",
      "Thread Thread 1 finished\n",
      "All threads completed\n"
     ]
    }
   ],
   "source": [
    "import threading # Import the threading module\n",
    "import time # Import the time module for sleep functionality \n",
    "\n",
    "# Define a simple function for the thread to execute\n",
    "def print_numbers(thread_name, start, end, delay):\n",
    "    print(f\"Thread {thread_name} started\")\n",
    "    for i in range(start, end + 1):\n",
    "        time.sleep(delay)  # Simulate work with delay\n",
    "        print(f\"{thread_name}: {i}\")\n",
    "    print(f\"Thread {thread_name} finished\")\n",
    "\n",
    "# Thread lifecycle and the threading.Thread class\n",
    "def thread_lifecycle_example():\n",
    "    # Create threads using the threading.Thread class\n",
    "    thread1 = threading.Thread(target=print_numbers, args=(\"Thread 1\", 1, 5, 1))\n",
    "    thread2 = threading.Thread(target=print_numbers, args=(\"Thread 2\", 6, 10, 0.5))\n",
    "\n",
    "    print(\"Starting threads...\")\n",
    "\n",
    "    # Start threads (this invokes the run method in threading.Thread)\n",
    "    thread1.start()  # Thread 1 will start running\n",
    "    thread2.start()  # Thread 2 will start running concurrently\n",
    "\n",
    "    # Join threads (wait for them to complete)\n",
    "    # The join() method ensures the main thread waits for both threads to finish\n",
    "    # before proceeding to the next line of code.\n",
    "    thread1.join()  # Blocks the main thread until thread1 finishes\n",
    "    thread2.join()  # Blocks the main thread until thread2 finishes\n",
    "    # since we have two threads, we can join them one after the other\n",
    "    # first join will block until thread1 finishes, then the second join will block until thread2 finishes\n",
    "    # which mean thread1 will finish first before thread2 finishes\n",
    "    # then execution will continue after both threads are done which is a sequential execution\n",
    "    # if we want them to run concurrently, we can start them both and join them both\n",
    "    # for example we can use a for loop to join them both\n",
    "    # for thread in [thread1, thread2]:\n",
    "    #     thread.join()\n",
    "    \n",
    "\n",
    "    print(\"All threads completed\")\n",
    "\n",
    "# Run the example\n",
    "if __name__ == \"__main__\":\n",
    "    thread_lifecycle_example()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key Concepts Highlighted:\n",
    "\n",
    "# Thread Creation: Two threads are created to perform tasks concurrently.\n",
    "# Thread Starting: Both threads are started using the start() method.\n",
    "# Join: The join() method ensures that the main program waits for both threads to complete before proceeding.\n",
    "# Concurrency: The output from both threads is interleaved, demonstrating that they are running concurrently.\n",
    "# Thread Lifecycle: The threads start, execute their tasks, and terminate. The main thread waits for them to complete before continuing execution.\n",
    "# This example provides a solid foundation in basic threading concepts in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Thread Safety: Managing race conditions and synchronizing access to shared resources \n",
    "# using locks is crucial in multithreading to avoid inconsistent or incorrect results.\n",
    "# When multiple threads access and modify shared data concurrently, race conditions may arise.\n",
    "# Race conditions occur when the outcome depends on the order in which threads execute. \n",
    "# This leads to unpredictable and incorrect results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenario 1: Race Condition Without Lock\n",
    "# In this scenario, two threads increment a shared counter. Without synchronization, \n",
    "# this can lead to race conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "# Shared resource (counter)\n",
    "counter = 0\n",
    "\n",
    "# Function to increment the counter\n",
    "def increment_counter():\n",
    "    global counter\n",
    "    for _ in range(100000):\n",
    "        counter += 1\n",
    "\n",
    "# Create two threads that modify the shared counter\n",
    "thread1 = threading.Thread(target=increment_counter)\n",
    "thread2 = threading.Thread(target=increment_counter)\n",
    "\n",
    "# Start the threads\n",
    "thread1.start()\n",
    "thread2.start()\n",
    "\n",
    "# Wait for both threads to complete\n",
    "thread1.join()\n",
    "thread2.join()\n",
    "\n",
    "print(f\"Final counter value (without lock): {counter}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explanation:\n",
    "# Shared Resource (counter): Both threads increment the shared counter 100,000 times.\n",
    "# Race Condition: Since both threads are trying to update the counter at the same time, the result will be unpredictable and often incorrect.\n",
    "# Expected Outcome:\n",
    "# The correct final value should be 200,000 (because each thread increments the counter by 100,000). However, due to race conditions, the output may be much lower than expected because both threads are modifying the counter simultaneously, and some increments are overwritten or lost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenario 2: Using threading.Lock to Prevent Race Conditions\n",
    "# A lock ensures that only one thread can execute a block of code (critical section) at a time.\n",
    "#  This prevents race conditions by serializing access to shared resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "# Shared resource (counter)\n",
    "counter = 0\n",
    "lock = threading.Lock()  # Create a lock\n",
    "\n",
    "# Function to increment the counter with lock\n",
    "def increment_counter_safe():\n",
    "    global counter\n",
    "    for _ in range(100000):\n",
    "        with lock:  # Acquire the lock before modifying the shared resource\n",
    "            counter += 1\n",
    "\n",
    "# Create two threads that modify the shared counter safely\n",
    "thread1 = threading.Thread(target=increment_counter_safe)\n",
    "thread2 = threading.Thread(target=increment_counter_safe)\n",
    "\n",
    "# Start the threads\n",
    "thread1.start()\n",
    "thread2.start()\n",
    "\n",
    "# Wait for both threads to complete\n",
    "thread1.join()\n",
    "thread2.join()\n",
    "\n",
    "print(f\"Final counter value (with lock): {counter}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explanation:\n",
    "# Lock (lock = threading.Lock()): A lock is created to ensure only one thread can modify \n",
    "# the shared counter at a time.\n",
    "# Critical Section (with lock): The with lock statement acquires the lock before modifying \n",
    "# the counter. Other threads must wait until the lock is released before they can enter the \n",
    "# critical section.\n",
    "# Expected Outcome:\n",
    "# Since the lock prevents simultaneous access to the shared counter, the final value should \n",
    "# be 200,000 as expected, with no race conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenario 3: Using threading.RLock for Reentrant Locks\n",
    "# An RLock (reentrant lock) allows a thread to acquire the same lock multiple times without\n",
    "#  causing a deadlock. This is useful when a thread may need to re-enter the critical section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "# Shared resource (counter)\n",
    "counter = 0\n",
    "rlock = threading.RLock()  # Create a reentrant lock\n",
    "\n",
    "# Function to increment the counter with reentrant lock\n",
    "def increment_counter_reentrant():\n",
    "    global counter\n",
    "    with rlock:  # First lock\n",
    "        with rlock:  # Re-enter the lock (allowed by RLock)\n",
    "            for _ in range(100000):\n",
    "                counter += 1\n",
    "\n",
    "# Create two threads that modify the shared counter safely\n",
    "thread1 = threading.Thread(target=increment_counter_reentrant)\n",
    "thread2 = threading.Thread(target=increment_counter_reentrant)\n",
    "\n",
    "# Start the threads\n",
    "thread1.start()\n",
    "thread2.start()\n",
    "\n",
    "# Wait for both threads to complete\n",
    "thread1.join()\n",
    "thread2.join()\n",
    "\n",
    "print(f\"Final counter value (with RLock): {counter}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explanation:\n",
    "# RLock: Unlike a normal lock (Lock), an RLock can be acquired multiple times by the same \n",
    "# thread without causing a deadlock. In this example, the same lock is acquired twice (with\n",
    "# rlock: nested).\n",
    "\n",
    "# Critical Section: The shared counter is modified safely, even though the same thread\n",
    "#  re-enters the critical section.\n",
    "\n",
    "# Expected Outcome:\n",
    "# The final counter value should still be 200,000. The RLock allows multiple acquisitions \n",
    "# by the same thread, but it still protects shared data from being accessed by other threads \n",
    "# concurrently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenario 4: Improper Use of Lock Leading to Deadlock\n",
    "\n",
    "# Improper use of locks can lead to deadlock, where two or more threads are waiting \n",
    "# on each other to release locks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import time\n",
    "\n",
    "lock1 = threading.Lock()\n",
    "lock2 = threading.Lock()\n",
    "\n",
    "# Thread 1 tries to acquire lock1 and then lock2\n",
    "def thread1_task():\n",
    "    with lock1:\n",
    "        time.sleep(1)  # Simulate work\n",
    "        with lock2:\n",
    "            print(\"Thread 1 has lock1 and lock2\")\n",
    "\n",
    "# Thread 2 tries to acquire lock2 and then lock1\n",
    "def thread2_task():\n",
    "    with lock2:\n",
    "        time.sleep(1)  # Simulate work\n",
    "        with lock1:\n",
    "            print(\"Thread 2 has lock2 and lock1\")\n",
    "\n",
    "# Create threads\n",
    "thread1 = threading.Thread(target=thread1_task)\n",
    "thread2 = threading.Thread(target=thread2_task)\n",
    "\n",
    "# Start threads\n",
    "thread1.start()\n",
    "thread2.start()\n",
    "\n",
    "# Wait for threads to finish (this will never happen due to deadlock)\n",
    "thread1.join()\n",
    "thread2.join()\n",
    "\n",
    "print(\"This message will never print due to deadlock\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explanation:\n",
    "\n",
    "# Deadlock: Thread 1 acquires lock1 and waits for lock2, while Thread 2 acquires lock2 and waits\n",
    "#  for lock1. Both threads are stuck, waiting for the other to release the lock.\n",
    "\n",
    "# Solution: Avoid acquiring multiple locks or ensure locks are always acquired in a consistent order.\n",
    "# Outcome:\n",
    "# The program will hang indefinitely due to deadlock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key Concepts:\n",
    "# Race Condition: Multiple threads accessing/modifying shared data simultaneously without proper \n",
    "# synchronization, leading to unpredictable results.\n",
    "# Lock (threading.Lock): A basic synchronization primitive to prevent race conditions by allowing \n",
    "# only one thread to execute a critical section at a time.\n",
    "# RLock (threading.RLock): A reentrant lock that allows the same thread to acquire the lock multiple\n",
    "#  times without causing deadlock.\n",
    "# Deadlock: A situation where two or more threads are waiting for each other to release resources,\n",
    "#  causing them to freeze indefinitely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Deadlocks and Starvation in Multithreading\n",
    "# Deadlock:\n",
    "# A deadlock occurs when two or more threads are waiting for each other to release resources,\n",
    "#  resulting in a situation where none of the threads can proceed. For example, Thread A holds\n",
    "# Lock 1 and is waiting for Lock 2, while Thread B holds Lock 2 and is waiting for Lock 1. Both\n",
    "#  threads are stuck, and this creates a deadlock.\n",
    "\n",
    "# Thread Starvation:\n",
    "# Thread starvation happens when a low-priority thread is unable to get access to a resource \n",
    "# (CPU time or shared data) because higher-priority threads are continuously executing and \n",
    "# monopolizing the resource."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenario 1: Deadlock Example\n",
    "# In this example, we have two threads, each trying to acquire two locks in a different order,\n",
    "#  which leads to a deadlock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import time\n",
    "\n",
    "# Locks representing shared resources\n",
    "lock1 = threading.Lock()\n",
    "lock2 = threading.Lock()\n",
    "\n",
    "# Thread 1 tries to acquire lock1 and then lock2\n",
    "def thread1_task():\n",
    "    print(\"Thread 1: Trying to acquire Lock 1\")\n",
    "    with lock1:\n",
    "        print(\"Thread 1: Acquired Lock 1\")\n",
    "        time.sleep(1)  # Simulate some work\n",
    "        print(\"Thread 1: Trying to acquire Lock 2\")\n",
    "        with lock2:\n",
    "            print(\"Thread 1: Acquired Lock 2\")\n",
    "\n",
    "# Thread 2 tries to acquire lock2 and then lock1 (opposite order)\n",
    "def thread2_task():\n",
    "    print(\"Thread 2: Trying to acquire Lock 2\")\n",
    "    with lock2:\n",
    "        print(\"Thread 2: Acquired Lock 2\")\n",
    "        time.sleep(1)  # Simulate some work\n",
    "        print(\"Thread 2: Trying to acquire Lock 1\")\n",
    "        with lock1:\n",
    "            print(\"Thread 2: Acquired Lock 1\")\n",
    "\n",
    "# Create threads\n",
    "thread1 = threading.Thread(target=thread1_task)\n",
    "thread2 = threading.Thread(target=thread2_task)\n",
    "\n",
    "# Start threads\n",
    "thread1.start()\n",
    "thread2.start()\n",
    "\n",
    "# Wait for threads to finish\n",
    "thread1.join()\n",
    "thread2.join()\n",
    "\n",
    "print(\"Both threads completed (this will never print due to deadlock)\")\n",
    "\n",
    "# Explanation:\n",
    "# Thread 1 acquires Lock 1 and waits for Lock 2.\n",
    "# Thread 2 acquires Lock 2 and waits for Lock 1.\n",
    "# Both threads are stuck waiting for each other to release their locks, causing a deadlock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution: Preventing Deadlocks by Acquiring Locks in a Defined Order\n",
    "\n",
    "# To avoid deadlock, we can enforce a strict ordering when acquiring multiple locks.\n",
    "# For example, both threads should always acquire Lock 1 before Lock 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import time\n",
    "\n",
    "# Locks representing shared resources\n",
    "lock1 = threading.Lock()\n",
    "lock2 = threading.Lock()\n",
    "\n",
    "# Thread 1 acquires locks in defined order (lock1, lock2)\n",
    "def thread1_task():\n",
    "    print(\"Thread 1: Trying to acquire Lock 1\")\n",
    "    with lock1:\n",
    "        print(\"Thread 1: Acquired Lock 1\")\n",
    "        time.sleep(1)\n",
    "        print(\"Thread 1: Trying to acquire Lock 2\")\n",
    "        with lock2:\n",
    "            print(\"Thread 1: Acquired Lock 2\")\n",
    "\n",
    "# Thread 2 also acquires locks in the same order (lock1, lock2)\n",
    "def thread2_task():\n",
    "    print(\"Thread 2: Trying to acquire Lock 1\")\n",
    "    with lock1:\n",
    "        print(\"Thread 2: Acquired Lock 1\")\n",
    "        time.sleep(1)\n",
    "        print(\"Thread 2: Trying to acquire Lock 2\")\n",
    "        with lock2:\n",
    "            print(\"Thread 2: Acquired Lock 2\")\n",
    "\n",
    "# Create threads\n",
    "thread1 = threading.Thread(target=thread1_task)\n",
    "thread2 = threading.Thread(target=thread2_task)\n",
    "\n",
    "# Start threads\n",
    "thread1.start()\n",
    "thread2.start()\n",
    "\n",
    "# Wait for threads to finish\n",
    "thread1.join()\n",
    "thread2.join()\n",
    "\n",
    "print(\"Both threads completed successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explanation:\n",
    "\n",
    "# Both threads now acquire locks in the same order (lock1 → lock2), preventing deadlocks.\n",
    "# If Thread 1 acquires lock1, Thread 2 must wait for lock1 to be released before it can proceed,\n",
    "#  ensuring there is no circular waiting.\n",
    "\n",
    "# Outcome:\n",
    "# The program will execute without deadlock, and the message \"Both threads completed successfully\"\n",
    "#  will print."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenario 2: Thread Starvation Example\n",
    "\n",
    "# In thread starvation, low-priority threads do not get a chance to execute because higher-priority\n",
    "# threads continuously monopolize the resources. In Python, we don't have thread priorities directly,\n",
    "# but we can simulate starvation by having threads that take much longer to release resources or \n",
    "# run without yielding control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import time\n",
    "\n",
    "# Shared resource\n",
    "lock = threading.Lock()\n",
    "\n",
    "# High-priority thread that monopolizes the lock for a long time\n",
    "def high_priority_task():\n",
    "    while True:\n",
    "        with lock:\n",
    "            print(\"High Priority Thread: Working\")\n",
    "            time.sleep(2)  # Hold the lock for 2 seconds, simulating a long task\n",
    "\n",
    "# Low-priority thread that tries to access the lock\n",
    "def low_priority_task():\n",
    "    while True:\n",
    "        with lock:\n",
    "            print(\"Low Priority Thread: Working\")\n",
    "            time.sleep(0.1)  # Hold the lock for a short time\n",
    "\n",
    "# Create and start threads\n",
    "high_priority_thread = threading.Thread(target=high_priority_task)\n",
    "low_priority_thread = threading.Thread(target=low_priority_task)\n",
    "\n",
    "# Start the high-priority thread first (simulating CPU hogging)\n",
    "high_priority_thread.start() # This thread will continuously hold the lock\n",
    "time.sleep(0.5)  # Give the high-priority thread a head start\n",
    "low_priority_thread.start() # Start the low-priority thread\n",
    "# only after the high-priority thread has started and held the lock for 0.5 seconds \n",
    "# the low-priority thread will start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explanation:\n",
    "# High-priority thread: Simulates a thread that holds the lock for a long time (2 seconds),\n",
    "#  monopolizing the shared resource.\n",
    "# Low-priority thread: Tries to acquire the lock but can only do so for very brief periods \n",
    "# (0.1 seconds) because the high-priority thread quickly reacquires the lock.\n",
    "# Outcome:\n",
    "# The low-priority thread will get very few chances to execute, leading to thread starvation.\n",
    "\n",
    "# The high-priority thread keeps monopolizing the resource, preventing the low-priority thread\n",
    "#  from accessing it frequently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution: Avoiding Starvation Using Time-Slicing or Yielding\n",
    "# One solution to thread starvation is to introduce periodic yielding or reduce the time the high-priority thread holds the lock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import time\n",
    "\n",
    "# Shared resource\n",
    "lock = threading.Lock()\n",
    "\n",
    "# High-priority thread that monopolizes the lock but yields control\n",
    "def high_priority_task():\n",
    "    while True:\n",
    "        with lock:\n",
    "            print(\"High Priority Thread: Working\")\n",
    "            time.sleep(0.5)  # Hold the lock for less time to allow other threads\n",
    "\n",
    "# Low-priority thread that tries to access the lock\n",
    "def low_priority_task():\n",
    "    while True:\n",
    "        with lock:\n",
    "            print(\"Low Priority Thread: Working\")\n",
    "            time.sleep(0.1)\n",
    "\n",
    "# Create and start threads\n",
    "high_priority_thread = threading.Thread(target=high_priority_task)\n",
    "low_priority_thread = threading.Thread(target=low_priority_task)\n",
    "\n",
    "# Start both threads\n",
    "high_priority_thread.start()\n",
    "time.sleep(0.5)  # Give the high-priority thread a head start\n",
    "low_priority_thread.start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of Key Concepts:\n",
    "# Deadlock: Happens when two or more threads wait on each other to release resources, \n",
    "# resulting in a standstill.\n",
    "# Prevention: Always acquire locks in a consistent order to avoid circular waiting.\n",
    "# Thread Starvation: Occurs when a low-priority thread doesn't get sufficient CPU time \n",
    "# because other threads continuously hog resources.\n",
    "# Solution: Use time-slicing, yielding, or ensure fair access to resources by not holding \n",
    "# locks for long periods.\n",
    "# Understanding and managing these issues is critical for writing efficient, safe, and \n",
    "# reliable multithreaded applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overview of ThreadPoolExecutor\n",
    "\n",
    "# ThreadPoolExecutor is a part of the concurrent.futures module in Python, \n",
    "# which provides a high-level interface for asynchronously executing callables using threads.\n",
    "#  It allows you to create a pool of threads and manage them efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import time\n",
    "\n",
    "# A simple function that simulates a task\n",
    "def task(n):\n",
    "    time.sleep(n)\n",
    "    return f'Task completed in {n} seconds'\n",
    "\n",
    "# Using ThreadPoolExecutor\n",
    "def main():\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:\n",
    "        # Here executor will manage a pool of 3 threads to execute tasks concurrently \n",
    "\n",
    "        # Submit multiple tasks to the pool\n",
    "        # Imagine we have 5 tasks with varying sleep times (1 to 5 seconds) \n",
    "        futures = [executor.submit(task, i) for i in range(1, 6)]\n",
    "        # Here executor will submit the tasks to the pool and return a list of Future objects\n",
    "        # since we got 3 workers, the first 3 tasks will be executed concurrently,\n",
    "        # and the remaining tasks will wait until a worker is free\n",
    "        # 4 and 5 will wait until 1, 2, and 3 are completed before they can start executing\n",
    "\n",
    "        # Collect results as they complete\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            print(future.result()) # This will print the result of each task as it completes\n",
    "            # So here each task is a Future object, and we can call result() on it to get the return value\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explanation\n",
    "# Function Definition: The task function simulates a task that takes n seconds to complete by sleeping for that duration.\n",
    "\n",
    "# ThreadPoolExecutor:\n",
    "\n",
    "# We create an instance of ThreadPoolExecutor with max_workers=3, meaning up to 3 threads can run concurrently.\n",
    "# The with statement ensures proper cleanup of threads when done.\n",
    "# Submitting Tasks:\n",
    "\n",
    "# We submit tasks to the pool using executor.submit(), which returns a Future object for each task.\n",
    "# In this case, we submit 5 tasks, where each task sleeps for 1 to 5 seconds.\n",
    "# Collecting Results:\n",
    "\n",
    "# We use concurrent.futures.as_completed() to iterate over the completed futures as they finish, allowing us to print results in the order they complete, not the order they were submitted.\n",
    "# Possible Data Scenarios\n",
    "# Variable Task Durations:\n",
    "\n",
    "# Tasks may have different execution times, which can lead to some tasks finishing before others, as shown in the example.\n",
    "# Error Handling:\n",
    "\n",
    "# You might want to handle exceptions if a task fails. You can catch exceptions when calling future.result()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for future in concurrent.futures.as_completed(futures):\n",
    "    try:\n",
    "        print(future.result())\n",
    "    except Exception as e:\n",
    "        print(f'Task generated an exception: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamic Task Submission:\n",
    "\n",
    "# Instead of a fixed list, you might generate tasks dynamically based on user input or data from a database.\n",
    "# Task Dependencies:\n",
    "\n",
    "# If tasks are dependent on the results of previous tasks, you would need to manage the order of execution, possibly by chaining futures.\n",
    "# Resource Limitation:\n",
    "\n",
    "# If tasks are resource-intensive (e.g., I/O bound), you might need to tune max_workers to avoid overwhelming the system.\n",
    "# Performance Monitoring:\n",
    "\n",
    "# Measure execution time for each task or the overall completion time, especially if tasks are expected to take varying amounts of time.\n",
    "# Conclusion\n",
    "# ThreadPoolExecutor provides a powerful way to manage threads and execute tasks concurrently. Understanding how to utilize it with different data scenarios will help you optimize performance in multithreaded applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this analogy:\n",
    "\n",
    "# Threads can run different functions (like playing different games) independently. Each thread (kid) has to be managed individually, which can get chaotic!\n",
    "\n",
    "# ThreadPoolExecutor: The Team of Helpers\n",
    "# Now imagine there’s a group of helpers (the ThreadPoolExecutor) who organize the kids on the playground.\n",
    "\n",
    "# Same Game: This time, let’s say all the kids want to play the same game, like hide and seek. The helpers assign kids to play this game.\n",
    "# Limited Helpers: There are only a few helpers available (let’s say 3), so even though there are many kids, only 3 can play at a time. The helpers will make sure everyone gets a turn without chaos.\n",
    "\n",
    "# In this analogy:\n",
    "\n",
    "# ThreadPoolExecutor efficiently manages tasks, allowing multiple kids (threads) to play the same game (function) but ensuring that not too many play at once. When a kid finishes, the helper quickly assigns another kid to join the game.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "# Threads: Kids playing different games independently. Each one has to manage themselves.\n",
    "# ThreadPoolExecutor: Helpers organizing kids to play the same game efficiently, with a limit on how many can play at once.\n",
    "# Function Execution\n",
    "# Threads can execute different functions (like playing different games).\n",
    "# ThreadPoolExecutor often executes the same function (like all kids playing hide and seek) but can also execute different functions if needed, depending on how you submit the tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can even combine both "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import threading\n",
    "import time\n",
    "\n",
    "# Function that simulates a task\n",
    "def independent_task(n):\n",
    "    time.sleep(n)\n",
    "    print(f'Independent task {n} completed.')\n",
    "\n",
    "# Function for the thread pool\n",
    "def pool_task(n):\n",
    "    time.sleep(n)\n",
    "    return f'Pool task {n} completed.'\n",
    "\n",
    "# Using both threads and ThreadPoolExecutor\n",
    "def main():\n",
    "    # Create some independent threads\n",
    "    independent_threads = []\n",
    "    for i in range(1, 4):\n",
    "        t = threading.Thread(target=independent_task, args=(i,))\n",
    "        independent_threads.append(t)\n",
    "        t.start()\n",
    "\n",
    "    # Using ThreadPoolExecutor for pooled tasks\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:\n",
    "        pool_futures = [executor.submit(pool_task, i) for i in range(1, 6)]\n",
    "        \n",
    "        # Collect results from the pool\n",
    "        for future in concurrent.futures.as_completed(pool_futures):\n",
    "            print(future.result())\n",
    "\n",
    "    # Wait for all independent threads to finish\n",
    "    for t in independent_threads:\n",
    "        t.join()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explanation\n",
    "# Independent Tasks:\n",
    "\n",
    "# We create and start some threads for independent tasks (e.g., independent_task). Each thread runs a task that simulates a delay based on the input.\n",
    "# ThreadPoolExecutor:\n",
    "\n",
    "# We use ThreadPoolExecutor to manage a set of tasks (e.g., pool_task). We submit multiple tasks to the executor, which manages them efficiently, allowing up to 2 tasks to run concurrently.\n",
    "# Collecting Results:\n",
    "\n",
    "# We collect results from the pool of tasks using as_completed(), which allows us to process results as they finish.\n",
    "# Joining Independent Threads:\n",
    "\n",
    "# Finally, we ensure all independent threads have completed by calling join() on each.\n",
    "# Benefits of Combining\n",
    "# Flexibility: You can handle different types of tasks (some that run independently and others that benefit from pooling).\n",
    "# Efficiency: The ThreadPoolExecutor helps optimize resource usage by controlling the number of concurrent tasks, while independent threads can still execute without being managed by the pool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daemon Threads\n",
    "# Background Workers: Daemon threads are like helpful assistants that work in the background.\n",
    "# Automatic Termination: If the main program (the boss) finishes its job, the daemon threads automatically stop working and leave.\n",
    "# Use Case: They are useful for tasks that don't need to finish if the main program exits, like background monitoring or logging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-Daemon Threads\n",
    "# Essential Workers: Non-daemon threads are like essential employees. They must finish their tasks before the main program can close.\n",
    "# Prevent Program Exit: If the main program finishes but non-daemon threads are still running, the program will wait for those threads to complete.\n",
    "# Use Case: They are ideal for tasks that are critical to the application, like processing user data or completing a transaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import time\n",
    "\n",
    "# Function for a daemon thread\n",
    "def daemon_task():\n",
    "    while True:\n",
    "        print(\"Daemon thread is running...\")\n",
    "        time.sleep(1)\n",
    "\n",
    "# Function for a non-daemon thread\n",
    "def non_daemon_task():\n",
    "    print(\"Non-daemon thread started.\")\n",
    "    time.sleep(5)\n",
    "    print(\"Non-daemon thread finished.\")\n",
    "\n",
    "# Creating threads\n",
    "daemon_thread = threading.Thread(target=daemon_task)\n",
    "non_daemon_thread = threading.Thread(target=non_daemon_task)\n",
    "\n",
    "# Set the daemon property to True\n",
    "daemon_thread.daemon = True\n",
    "\n",
    "# Start the threads\n",
    "daemon_thread.start()\n",
    "non_daemon_thread.start()\n",
    "\n",
    "# Wait for the non-daemon thread to finish\n",
    "non_daemon_thread.join() # Here we are waiting for the non-daemon thread to finish\n",
    "\n",
    "print(\"Main program is exiting...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explanation of the Code\n",
    "# Daemon Thread:\n",
    "\n",
    "# The daemon_task function runs indefinitely, printing a message every second.\n",
    "# We set daemon_thread.daemon = True to make it a daemon thread.\n",
    "# Non-Daemon Thread:\n",
    "\n",
    "# The non_daemon_task function runs for 5 seconds, then finishes.\n",
    "# It does not have the daemon property set, so it is a non-daemon thread.\n",
    "# Thread Execution:\n",
    "\n",
    "# When you start both threads, the main program will continue running.\n",
    "# However, when the non-daemon thread finishes (after 5 seconds), the main program will exit, and the daemon thread will be terminated immediately.\n",
    "\n",
    "# Summary\n",
    "# Daemon Threads: Run in the background, automatically terminated when the main program exits. Useful for non-essential tasks.\n",
    "# Non-Daemon Threads: Must finish their work before the main program can exit. Critical for tasks that need to be completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ere are simple examples demonstrating multithreading use cases in data engineering: batch data processing, ETL pipelines, real-time data processing, and API rate limiting.\n",
    "\n",
    "# 1. Batch Data Processing\n",
    "# In this example, we simulate reading data from multiple partitions concurrently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import time\n",
    "\n",
    "# Simulated function to read data from a partition\n",
    "def read_partition(partition_id):\n",
    "    print(f\"Starting to read from partition {partition_id}\")\n",
    "    time.sleep(2)  # Simulate time taken to read data\n",
    "    print(f\"Finished reading from partition {partition_id}\")\n",
    "\n",
    "# Simulating reading from multiple partitions\n",
    "def batch_data_processing():\n",
    "    partitions = [1, 2, 3, 4]  # Simulated partition IDs\n",
    "    threads = []\n",
    "\n",
    "    for partition in partitions:\n",
    "        thread = threading.Thread(target=read_partition, args=(partition,))\n",
    "        threads.append(thread)\n",
    "        thread.start()\n",
    "\n",
    "    # Wait for all threads to finish\n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "\n",
    "    print(\"Batch data processing completed.\")\n",
    "\n",
    "# Run the example\n",
    "batch_data_processing()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ETL Pipelines\n",
    "# This example shows using multithreading to perform data transformation and loading into a database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming data1\n",
      "Loading Transformed data1 to databaseTransforming data2\n",
      "\n",
      "Loaded Transformed data1\n",
      "Loading Transformed data2 to database\n",
      "Transforming data3\n",
      "Loaded Transformed data2\n",
      "Loading Transformed data3 to database\n",
      "Loaded Transformed data3\n",
      "ETL pipeline completed.\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import time\n",
    "\n",
    "# Simulated function to transform data\n",
    "def transform_data(data):\n",
    "    print(f\"Transforming {data}\")\n",
    "    time.sleep(1)  # Simulate time taken to transform data\n",
    "    return f\"Transformed {data}\"\n",
    "\n",
    "# Simulated function to load data into a database\n",
    "def load_to_database(transformed_data):\n",
    "    print(f\"Loading {transformed_data} to database\")\n",
    "    time.sleep(1)  # Simulate loading time\n",
    "    print(f\"Loaded {transformed_data}\")\n",
    "\n",
    "# Simulating ETL process\n",
    "def etl_pipeline(data_list):\n",
    "    threads = []\n",
    "\n",
    "    for data in data_list:\n",
    "        # Transform data in a thread\n",
    "        transformed_data = transform_data(data)\n",
    "        # Load transformed data in another thread\n",
    "        thread = threading.Thread(target=load_to_database, args=(transformed_data,))\n",
    "        threads.append(thread)\n",
    "        thread.start()\n",
    "\n",
    "    # Wait for all threads to finish\n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "\n",
    "    print(\"ETL pipeline completed.\")\n",
    "\n",
    "# Run the example\n",
    "etl_pipeline([\"data1\", \"data2\", \"data3\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real-time Data Processing\n",
    "# In this example, we simulate processing data streams from multiple sources concurrently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import time\n",
    "\n",
    "# Simulated function to process a data stream\n",
    "def process_stream(source):\n",
    "    print(f\"Starting to process stream from {source}\")\n",
    "    for i in range(3):\n",
    "        time.sleep(1)  # Simulate processing time\n",
    "        print(f\"Processed item {i + 1} from {source}\")\n",
    "    print(f\"Finished processing stream from {source}\")\n",
    "\n",
    "# Simulating real-time data processing\n",
    "def real_time_processing():\n",
    "    sources = [\"Source A\", \"Source B\", \"Source C\"]\n",
    "    threads = []\n",
    "\n",
    "    for source in sources:\n",
    "        thread = threading.Thread(target=process_stream, args=(source,))\n",
    "        threads.append(thread)\n",
    "        thread.start()\n",
    "\n",
    "    # Wait for all threads to finish\n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "\n",
    "    print(\"Real-time data processing completed.\")\n",
    "\n",
    "# Run the example\n",
    "real_time_processing()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API Rate Limiting\n",
    "# This example demonstrates managing multiple API calls while respecting rate limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import time\n",
    "import random\n",
    "\n",
    "# Simulated function to call an API\n",
    "def call_api(api_id):\n",
    "    print(f\"API call to {api_id} started\")\n",
    "    time.sleep(random.uniform(0.5, 1.5))  # Simulate varying response times\n",
    "    print(f\"API call to {api_id} completed\")\n",
    "\n",
    "# Simulating API rate limiting\n",
    "def api_rate_limiting():\n",
    "    api_ids = [\"API 1\", \"API 2\", \"API 3\", \"API 4\"]\n",
    "    threads = []\n",
    "\n",
    "    for api_id in api_ids:\n",
    "        thread = threading.Thread(target=call_api, args=(api_id,))\n",
    "        threads.append(thread)\n",
    "        thread.start()\n",
    "\n",
    "        # Introducing a delay to respect rate limit\n",
    "        time.sleep(1)  # Delay to avoid exceeding rate limits\n",
    "        # This will ensure that we are not exceeding the allowed number of requests to the API\n",
    "        # within a certain time frame.\n",
    "\n",
    "    # Wait for all threads to finish\n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "\n",
    "    print(\"All API calls completed.\")\n",
    "\n",
    "# Run the example\n",
    "api_rate_limiting()\n",
    "\n",
    "# what this program does is it simulates a scenario where we have multiple threads\n",
    "#  that are performing different tasks concurrently.\n",
    "\n",
    "# In the first example, we simulate reading data from multiple partitions concurrently.\n",
    "# In the second example, we simulate an ETL pipeline where data is transformed and loaded\n",
    "#  into a database.\n",
    "\n",
    "# In the third example, we simulate real-time data processing from multiple sources.\n",
    "# In the fourth example, we demonstrate managing multiple API calls while respecting rate limits.\n",
    "# These examples illustrate how multithreading can be effectively used in data engineering tasks\n",
    "\n",
    "\n",
    "# we are inducing a delay to respect the rate limit of the API calls. \n",
    "# which means we are ensuring that we are not exceeding the allowed number of requests to the API\n",
    "#  within a certain time frame."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
